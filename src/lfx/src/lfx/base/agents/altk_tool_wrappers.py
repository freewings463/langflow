"""
æ¨¡å—åç§°ï¼š`ALTK` å·¥å…·åŒ…è£…å™¨ä¸æ ¡éªŒé€‚é…

æœ¬æ¨¡å—æä¾› `ALTK` å·¥å…·åŒ…è£…å™¨å®ç°ä¸ `SPARC` éªŒè¯åŒ…è£…é€»è¾‘ï¼Œä¸»è¦ç”¨äºåœ¨ä»£ç†è°ƒç”¨å·¥å…·å‰è¿›è¡Œ
å‚æ•°æ ¡éªŒã€ä¸Šä¸‹æ–‡è®°å½•ä¸é”™è¯¯æ¢å¤ã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
- `Pydantic` å‚æ•°åˆ° `OpenAI` `schema` çš„è½¬æ¢
- `SPARC` åæ€éªŒè¯ä¸æ‹’ç»æ¶ˆæ¯æ„å»º
- åŒ…è£…å™¨é“¾è·¯çš„åˆ›å»ºã€åµŒå¥—ä¸è§£åŒ…

å…³é”®ç»„ä»¶ï¼š
- `ValidatedTool`ï¼šå¸¦ SPARC éªŒè¯çš„å·¥å…·åŒ…è£…å™¨
- `PreToolValidationWrapper`ï¼šæ‰§è¡Œå‰éªŒè¯åŒ…è£…å™¨
- `PostToolProcessor`ï¼šæ‰§è¡Œåå¤„ç†ä»£ç†å·¥å…·
- `PostToolProcessingWrapper`ï¼šæ‰§è¡Œåå¤„ç†åŒ…è£…å™¨

è®¾è®¡èƒŒæ™¯ï¼šå·¥å…·åè®®ä¸æ ¡éªŒé€»è¾‘åˆ†æ•£ï¼Œéœ€è¦é›†ä¸­é€‚é…ä¸å¤ç”¨ã€‚
æ³¨æ„äº‹é¡¹ï¼šåŒ…è£…å™¨åµŒå¥—æ·±åº¦å— `_MAX_WRAPPER_DEPTH` é™åˆ¶ï¼›éªŒè¯å¤±è´¥ä¼šå›é€€åˆ°ç›´æ¥æ‰§è¡Œã€‚
"""

# å†³ç­–ï¼šæœ€å¤§åŒ…è£…å™¨åµŒå¥—æ·±åº¦
# é—®é¢˜ï¼šé˜²æ­¢æ— é™å¾ªç¯
# æ–¹æ¡ˆï¼šè®¾ç½®æœ€å¤§åŒ…è£…å™¨åµŒå¥—æ·±åº¦é™åˆ¶
# ä»£ä»·ï¼šé™åˆ¶äº†åµŒå¥—å±‚æ•°
# é‡è¯„ï¼šå½“éœ€è¦æ›´æ·±çš„åµŒå¥—æ—¶é‡æ–°è¯„ä¼°
_MAX_WRAPPER_DEPTH = 10


def _convert_pydantic_type_to_json_schema_type(param_info: dict) -> dict:
    """å°† Pydantic å‚æ•°ä¿¡æ¯è½¬æ¢ä¸º OpenAI å‡½æ•°è°ƒç”¨ JSON æ¨¡å¼æ ¼å¼

    å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
    1) å¤„ç†ç®€å•ç±»å‹ï¼ˆå­—ç¬¦ä¸²ã€æ•°å­—ã€æ•´æ•°ã€å¸ƒå°”å€¼ç­‰ï¼‰
    2) å¤„ç†å¤æ‚ç±»å‹ï¼ˆanyOfã€oneOfã€allOf ç­‰è”åˆç±»å‹ï¼‰
    3) è¿”å›å…¼å®¹ OpenAI å‡½æ•°è°ƒç”¨æ ¼å¼çš„å­—å…¸

    å¼‚å¸¸æµï¼šæ— æ³•ç¡®å®šç±»å‹æ—¶è¿”å›å­—ç¬¦ä¸²ç±»å‹çš„é»˜è®¤å€¼ã€‚
    æ€§èƒ½ç“¶é¢ˆï¼šé€’å½’å¤„ç†å¤æ‚ç±»å‹æ—¶ã€‚
    æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "Could not determine type for param_info"ã€‚
    
    å¥‘çº¦ï¼š
    - è¾“å…¥ï¼šæ¥è‡ª LangChain å·¥å…·å‚æ•°çš„ä¿¡æ¯å­—å…¸
    - è¾“å‡ºï¼šä¸ OpenAI å‡½æ•°è°ƒç”¨æ ¼å¼å…¼å®¹çš„ç±»å‹å­—å…¸
    - å‰¯ä½œç”¨ï¼šæ— 
    - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœæ— æ³•ç¡®å®šç±»å‹ï¼Œåˆ™è¿”å›é»˜è®¤å­—ç¬¦ä¸²ç±»å‹
    """
    # å…ˆå¤„ç†ç®€å•ç±»å‹
    if "type" in param_info:
        schema_type = param_info["type"]

        # ç›´æ¥ç±»å‹æ˜ å°„
        if schema_type in ("string", "number", "integer", "boolean", "null", "object"):
            return {
                "type": schema_type,
                "description": param_info.get("description", ""),
            }

        # æ•°ç»„ç±»å‹
        if schema_type == "array":
            result = {"type": "array", "description": param_info.get("description", "")}
            # è‹¥å­˜åœ¨ `items` åˆ™è¡¥å……å…¶ `schema`
            if "items" in param_info:
                items_schema = _convert_pydantic_type_to_json_schema_type(param_info["items"])
                result["items"] = items_schema
            return result

    # å¤„ç† `anyOf` çš„è”åˆç±»å‹ï¼ˆå¦‚ `list[str] | None`ï¼‰
    if "anyOf" in param_info:
        # æ‰¾åˆ°æœ€å…·ä½“çš„éç©ºç±»å‹
        for variant in param_info["anyOf"]:
            if variant.get("type") == "null":
                continue  # Skip null variants

            # å¤„ç†è¯¥éç©ºå˜ä½“
            converted = _convert_pydantic_type_to_json_schema_type(variant)
            converted["description"] = param_info.get("description", "")

            # å­˜åœ¨é»˜è®¤å€¼æ—¶è§†ä¸ºå¯é€‰
            if "default" in param_info:
                converted["default"] = param_info["default"]

            return converted

    # å¤„ç† `oneOf`ï¼ˆç±»ä¼¼ `anyOf`ï¼‰
    if "oneOf" in param_info:
        # å–ç¬¬ä¸€ä¸ªéç©ºé€‰é¡¹
        for variant in param_info["oneOf"]:
            if variant.get("type") != "null":
                converted = _convert_pydantic_type_to_json_schema_type(variant)
                converted["description"] = param_info.get("description", "")
                return converted

    # å¤„ç† `allOf`ï¼ˆäº¤é›†ç±»å‹ï¼‰
    if param_info.get("allOf"):
        # æš‚æ—¶å–ç¬¬ä¸€ä¸ª `schema`
        converted = _convert_pydantic_type_to_json_schema_type(param_info["allOf"][0])
        converted["description"] = param_info.get("description", "")
        return converted

    # å…œåº•ï¼šå°è¯•ä» `title` æ¨æ–­ï¼Œå¦åˆ™é»˜è®¤å­—ç¬¦ä¸²
    logger.debug(f"Could not determine type for param_info: {param_info}")
    return {
        "type": "string",  # Safe fallback
        "description": param_info.get("description", ""),
    }


class ValidatedTool(ALTKBaseTool):
    """ä½¿ç”¨ SPARC åæ€åœ¨æ‰§è¡Œå‰éªŒè¯è°ƒç”¨çš„åŒ…è£…å·¥å…·

    å¦‚æœ SPARC ä¸å¯ç”¨ï¼Œåˆ™é€€å›åˆ°ç®€å•éªŒè¯ã€‚
    
    å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
    1) å‡†å¤‡å·¥å…·è°ƒç”¨ä»¥è¿›è¡Œ SPARC éªŒè¯
    2) è¿è¡Œ SPARC éªŒè¯è¿‡ç¨‹
    3) æ ¹æ®éªŒè¯ç»“æœæ‰§è¡Œæˆ–æ‹’ç»å·¥å…·è°ƒç”¨
    
    å¼‚å¸¸æµï¼šSPARC éªŒè¯å¤±è´¥æ—¶ç›´æ¥æ‰§è¡Œå·¥å…·ã€‚
    æ€§èƒ½ç“¶é¢ˆï¼šSPARC éªŒè¯è¿‡ç¨‹ã€‚
    æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "SPARC validation result"ã€"SPARC rejected tool call"ã€‚
    
    å¥‘çº¦ï¼š
    - è¾“å…¥ï¼šè¢«åŒ…è£…çš„å·¥å…·ã€ä»£ç†å’Œå…¶ä»–å‚æ•°
    - è¾“å‡ºï¼šValidatedTool å®ä¾‹
    - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ– SPARC åæ€ç»„ä»¶
    - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœéªŒè¯å¤±è´¥ï¼Œåˆ™è¿”å›æ ¼å¼åŒ–çš„æ‹’ç»æ¶ˆæ¯
    """

    sparc_component: Any | None = Field(default=None)
    conversation_context: list[BaseMessage] = Field(default_factory=list)
    tool_specs: list[dict] = Field(default_factory=list)
    validation_attempts: dict[str, int] = Field(default_factory=dict)
    current_conversation_context: list[BaseMessage] = Field(default_factory=list)
    previous_tool_calls_in_current_step: list[dict] = Field(default_factory=list)
    previous_reflection_messages: dict[str, str] = Field(default_factory=list)

    def __init__(
        self,
        wrapped_tool: BaseTool,
        agent,
        sparc_component=None,
        conversation_context=None,
        tool_specs=None,
        **kwargs,
    ):
        """åˆå§‹åŒ–éªŒè¯å·¥å…·

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šè¢«åŒ…è£…çš„å·¥å…·ã€ä»£ç†å’Œå…¶ä»–å‚æ•°
        - è¾“å‡ºï¼šValidatedTool å®ä¾‹
        - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ–çˆ¶ç±»å’Œæ‰€æœ‰å­—æ®µ
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼ŒæŠ›å‡ºç›¸åº”å¼‚å¸¸
        """
        super().__init__(
            name=wrapped_tool.name,
            description=wrapped_tool.description,
            wrapped_tool=wrapped_tool,
            sparc_component=sparc_component,
            conversation_context=conversation_context or [],
            tool_specs=tool_specs or [],
            agent=agent,
            **kwargs,
        )

    def _run(self, *args, **kwargs) -> str:
        """æ‰§è¡Œå¸¦éªŒè¯çš„å·¥å…·

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°
        - è¾“å‡ºï¼šå·¥å…·æ‰§è¡Œç»“æœå­—ç¬¦ä¸²
        - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ– SPARC åæ€ç»„ä»¶
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœæ‰§è¡Œå¤±è´¥ï¼ŒæŠ›å‡ºç›¸åº”å¼‚å¸¸
        """
        self.sparc_component = SPARCReflectionComponent(
            config=ComponentConfig(llm_client=self._get_altk_llm_object()),
            track=Track.FAST_TRACK,  # Use fast track for performance
            execution_mode=SPARCExecutionMode.SYNC,  # Use SYNC to avoid event loop conflicts
        )
        return self._validate_and_run(*args, **kwargs)

    @staticmethod
    def _custom_message_to_dict(message: BaseMessage) -> dict:
        """å°† BaseMessage è½¬æ¢ä¸ºå­—å…¸

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šBaseMessage å¯¹è±¡
        - è¾“å‡ºï¼šå­—å…¸è¡¨ç¤ºçš„æ¶ˆæ¯
        - å‰¯ä½œç”¨ï¼šæ— 
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœæ¶ˆæ¯ç±»å‹æ— æ•ˆï¼ŒæŠ›å‡º ValueError
        """
        if isinstance(message, BaseMessage):
            return message_to_dict(message)
        msg = f"Invalid message type: {type(message)}"
        logger.error(msg, exc_info=True)
        raise ValueError(msg) from None

    def _validate_and_run(self, *args, **kwargs) -> str:
        """ä½¿ç”¨ SPARC éªŒè¯å·¥å…·è°ƒç”¨å¹¶æ‰§è¡Œï¼ˆå¦‚æœæœ‰æ•ˆï¼‰

        å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
        1) å‡†å¤‡å·¥å…·è°ƒç”¨ä»¥è¿›è¡Œ SPARC éªŒè¯
        2) è¿è¡Œ SPARC éªŒè¯è¿‡ç¨‹
        3) æ ¹æ®éªŒè¯ç»“æœæ‰§è¡Œå·¥å…·æˆ–è¿”å›æ‹’ç»æ¶ˆæ¯

        å¼‚å¸¸æµï¼šSPARC éªŒè¯è¿‡ç¨‹ä¸­çš„å„ç§å¼‚å¸¸ã€‚
        æ€§èƒ½ç“¶é¢ˆï¼šSPARC éªŒè¯è¿‡ç¨‹ã€‚
        æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "SPARC validation result"ã€"Error during SPARC validation"ã€‚
        
        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°
        - è¾“å‡ºï¼šéªŒè¯ç»“æœæˆ–å·¥å…·æ‰§è¡Œç»“æœ
        - å‰¯ä½œç”¨ï¼šæ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡å’Œå·¥å…·è°ƒç”¨è®°å½•
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœéªŒè¯å¤±è´¥ï¼Œè¿”å›æ ¼å¼åŒ–çš„æ‹’ç»æ¶ˆæ¯ï¼›å¦‚æœæ‰§è¡Œå¤±è´¥ï¼ŒæŠ›å‡ºç›¸åº”å¼‚å¸¸
        """
        # åˆ¤æ–­æ˜¯å¦ç»•è¿‡éªŒè¯
        if not self.sparc_component:
            return self._execute_tool(*args, **kwargs)

        # å‡†å¤‡ `SPARC` éªŒè¯æ‰€éœ€çš„å·¥å…·è°ƒç”¨
        tool_call = {
            "id": str(uuid.uuid4()),
            "type": "function",
            "function": {
                "name": self.name,
                "arguments": json.dumps(self._prepare_arguments(*args, **kwargs)),
            },
        }

        if (
            isinstance(self.conversation_context, list)
            and self.conversation_context
            and isinstance(self.conversation_context[0], BaseMessage)
        ):
            logger.debug("Converting BaseMessages to list of dictionaries for conversation context of SPARC")
            self.conversation_context = [self._custom_message_to_dict(msg) for msg in self.conversation_context]

        logger.debug(
            f"Converted conversation context for SPARC for tool call:\n"
            f"{json.dumps(tool_call, indent=2)}\n{self.conversation_context=}"
        )

        try:
            # æ‰§è¡Œ `SPARC` éªŒè¯
            run_input = SPARCReflectionRunInput(
                messages=self.conversation_context + self.previous_tool_calls_in_current_step,
                tool_specs=self.tool_specs,
                tool_calls=[tool_call],
            )

            if self.current_conversation_context != self.conversation_context:
                logger.info("Updating conversation context for SPARC validation")
                self.current_conversation_context = self.conversation_context
                self.previous_tool_calls_in_current_step = []
            else:
                logger.info("Using existing conversation context for SPARC validation")
                self.previous_tool_calls_in_current_step.append(tool_call)

            # å·¥å…·è§„æ ¼ç¼ºå¤±æ—¶å¯é€‰æ‹©ç»•è¿‡
            if not self.tool_specs:
                logger.warning(f"No tool specs available for SPARC validation of {self.name}, executing directly")
                return self._execute_tool(*args, **kwargs)

            result = self.sparc_component.process(run_input, phase=AgentPhase.RUNTIME)
            logger.debug(f"SPARC validation result for tool {self.name}: {result.output.reflection_result}")

            # æ£€æŸ¥éªŒè¯ç»“æœ
            if result.output.reflection_result.decision.name == "APPROVE":
                logger.info(f"âœ… SPARC approved tool call for {self.name}")
                return self._execute_tool(*args, **kwargs)
            logger.info(f"âŒ SPARC rejected tool call for {self.name}")
            return self._format_sparc_rejection(result.output.reflection_result)

        except (AttributeError, TypeError, ValueError, RuntimeError) as e:
            logger.error(f"Error during SPARC validation: {e}")
            # éªŒè¯å‡ºé”™æ—¶ç›´æ¥æ‰§è¡Œ
            return self._execute_tool(*args, **kwargs)

    def _prepare_arguments(self, *args, **kwargs) -> dict[str, Any]:
        """ä¸º SPARC éªŒè¯å‡†å¤‡å‚æ•°

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°
        - è¾“å‡ºï¼šæ ¼å¼åŒ–çš„å‚æ•°å­—å…¸
        - å‰¯ä½œç”¨ï¼šç§»é™¤ä¸éœ€è¦çš„é…ç½®å‚æ•°
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœå‚æ•°å‡†å¤‡å¤±è´¥ï¼Œè¿”å›æ¸…ç†åçš„å…³é”®å­—å‚æ•°
        """
        # è‹¥åŒ…å« `config` å‚æ•°åˆ™ç§»é™¤ï¼ˆéªŒè¯ä¸éœ€è¦ï¼‰
        clean_kwargs = {k: v for k, v in kwargs.items() if k != "config"}

        # è‹¥æœ‰ä½ç½®å‚æ•°ï¼Œå°è¯•æ˜ å°„åˆ°å‚æ•°å
        if args and hasattr(self.wrapped_tool, "args_schema"):
            try:
                schema = self.wrapped_tool.args_schema
                field_source = None
                if hasattr(schema, "__fields__"):
                    field_source = schema.__fields__
                elif hasattr(schema, "model_fields"):
                    field_source = schema.model_fields
                if field_source:
                    field_names = list(field_source.keys())
                    for i, arg in enumerate(args):
                        if i < len(field_names):
                            clean_kwargs[field_names[i]] = arg
            except (AttributeError, KeyError, TypeError):
                # `schema` è§£æå¤±è´¥åˆ™ç›´æ¥ä½¿ç”¨ `kwargs`
                pass

        return clean_kwargs

    def _format_sparc_rejection(self, reflection_result) -> str:
        """å°† SPARC æ‹’ç»æ ¼å¼åŒ–ä¸ºæœ‰ç”¨çš„é”™è¯¯æ¶ˆæ¯

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šåæ€ç»“æœå¯¹è±¡
        - è¾“å‡ºï¼šæ ¼å¼åŒ–çš„é”™è¯¯æ¶ˆæ¯å­—ç¬¦ä¸²
        - å‰¯ä½œç”¨ï¼šæ— 
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœæ²¡æœ‰é—®é¢˜è®°å½•ï¼Œè¿”å›é€šç”¨é”™è¯¯æ¶ˆæ¯
        """
        if not reflection_result.issues:
            return "Error: Tool call validation failed - please review your approach and try again"

        error_parts = ["Tool call validation failed:"]

        for issue in reflection_result.issues:
            error_parts.append(f"\nâ€¢ {issue.explanation}")
            if issue.correction:
                try:
                    correction_data = issue.correction
                    if isinstance(correction_data, dict):
                        if "corrected_function_name" in correction_data:
                            error_parts.append(f"  ğŸ’¡ Suggested function: {correction_data['corrected_function_name']}")
                        elif "tool_call" in correction_data:
                            suggested_args = correction_data["tool_call"].get("arguments", {})
                            error_parts.append(f"  ğŸ’¡ Suggested parameters: {suggested_args}")
                except (AttributeError, KeyError, TypeError):
                    # æ ¡æ­£è§£æå¤±è´¥åˆ™è·³è¿‡
                    pass

        error_parts.append("\nPlease adjust your approach and try again.")
        return "\n".join(error_parts)

    def update_context(self, conversation_context: list[BaseMessage]):
        """æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šBaseMessage å¯¹è±¡åˆ—è¡¨
        - è¾“å‡ºï¼šæ— 
        - å‰¯ä½œç”¨ï¼šæ›´æ–° conversation_context å­—æ®µ
        - å¤±è´¥è¯­ä¹‰ï¼šæ— 
        """
        self.conversation_context = conversation_context


class PreToolValidationWrapper(BaseToolWrapper):
    """æ·»åŠ é¢„å·¥å…·éªŒè¯åŠŸèƒ½çš„å·¥å…·åŒ…è£…å™¨

    æ­¤åŒ…è£…å™¨åœ¨æ‰§è¡Œå‰ä½¿ç”¨ SPARC åæ€ç»„ä»¶éªŒè¯å·¥å…·è°ƒç”¨çš„é€‚å½“æ€§å’Œæ­£ç¡®æ€§ã€‚
    
    å¥‘çº¦ï¼š
    - è¾“å…¥ï¼šBaseTool å¯¹è±¡åŠé¢å¤–å‚æ•°
    - è¾“å‡ºï¼šå¸¦æœ‰éªŒè¯åŠŸèƒ½çš„åŒ…è£…å·¥å…·
    - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ– SPARC éªŒè¯ç»„ä»¶
    - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœåŒ…è£…å¤±è´¥ï¼Œè¿”å›åŸå§‹å·¥å…·
    """

    def __init__(self):
        """åˆå§‹åŒ–é¢„å·¥å…·éªŒè¯åŒ…è£…å™¨

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šæ— 
        - è¾“å‡ºï¼šPreToolValidationWrapper å®ä¾‹
        - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ–å·¥å…·è§„æ ¼åˆ—è¡¨
        - å¤±è´¥è¯­ä¹‰ï¼šæ— 
        """
        self.tool_specs = []

    def wrap_tool(self, tool: BaseTool, **kwargs) -> BaseTool:
        """ä½¿ç”¨éªŒè¯åŠŸèƒ½åŒ…è£…å·¥å…·

        å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
        1) æ£€æŸ¥å·¥å…·æ˜¯å¦å·²è¢«åŒ…è£…
        2) éªŒè¯å¿…è¦å‚æ•°æ˜¯å¦å­˜åœ¨
        3) åº”ç”¨éªŒè¯åŒ…è£…å™¨

        å¼‚å¸¸æµï¼šç¼ºå°‘ä»£ç†å‚æ•°æ—¶è¿”å›åŸå§‹å·¥å…·ã€‚
        æ€§èƒ½ç“¶é¢ˆï¼šæ— æ˜¾è‘—æ€§èƒ½ç“¶é¢ˆã€‚
        æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "Cannot wrap tool with PreToolValidationWrapper"ã€‚
        
        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šBaseTool å¯¹è±¡å’Œå…³é”®å­—å‚æ•°
        - è¾“å‡ºï¼šåŒ…è£…åçš„ BaseTool å¯¹è±¡
        - å‰¯ä½œç”¨ï¼šå¯èƒ½æ›´æ–°ç°æœ‰éªŒè¯å·¥å…·çš„ä¸Šä¸‹æ–‡
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœä»£ç†å‚æ•°ç¼ºå¤±ï¼Œè¿”å›åŸå§‹å·¥å…·
        """
        if isinstance(tool, ValidatedTool):
            # å·²åŒ…è£…åˆ™ä»…æ›´æ–°ä¸Šä¸‹æ–‡ä¸å·¥å…·è§„æ ¼
            tool.tool_specs = self.tool_specs
            if "conversation_context" in kwargs:
                tool.update_context(kwargs["conversation_context"])
            logger.debug(f"Updated existing ValidatedTool {tool.name} with {len(self.tool_specs)} tool specs")
            return tool

        agent = kwargs.get("agent")

        if not agent:
            logger.warning("Cannot wrap tool with PreToolValidationWrapper: missing 'agent'")
            return tool

        # ä½¿ç”¨éªŒè¯åŒ…è£…å™¨åŒ…è£¹
        return ValidatedTool(
            wrapped_tool=tool,
            agent=agent,
            tool_specs=self.tool_specs,
            conversation_context=kwargs.get("conversation_context", []),
        )

    @staticmethod
    def convert_langchain_tools_to_sparc_tool_specs_format(
        tools: list[BaseTool],
    ) -> list[dict]:
        """å°† LangChain å·¥å…·è½¬æ¢ä¸º SPARC éªŒè¯çš„ OpenAI å‡½æ•°è°ƒç”¨æ ¼å¼

        å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
        1) éå† LangChain å·¥å…·åˆ—è¡¨
        2) ä¸ºæ¯ä¸ªå·¥å…·æ„å»º OpenAI å‡½æ•°è°ƒç”¨æ ¼å¼çš„è§„æ ¼
        3) æå–å‚æ•°å¹¶è½¬æ¢ä¸º JSON æ¨¡å¼æ ¼å¼

        å¼‚å¸¸æµï¼šå·¥å…·è½¬æ¢å¤±è´¥æ—¶åˆ›å»ºæœ€å°è§„æ ¼ã€‚
        æ€§èƒ½ç“¶é¢ˆï¼šé€’å½’å¤„ç†å¤æ‚å‚æ•°ç±»å‹æ—¶ã€‚
        æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "Could not convert tool"ã€"No tool specs were generated"ã€‚
        
        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šLangChain BaseTool å®ä¾‹åˆ—è¡¨
        - è¾“å‡ºï¼šOpenAI å‡½æ•°è°ƒç”¨æ ¼å¼çš„å·¥å…·è§„æ ¼åˆ—è¡¨
        - å‰¯ä½œç”¨ï¼šæ— 
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœæ— æ³•ç”Ÿæˆä»»ä½•è§„æ ¼ï¼Œè®°å½•é”™è¯¯æ—¥å¿—
        """
        tool_specs = []

        for i, tool in enumerate(tools):
            try:
                # å¤„ç†åµŒå¥—åŒ…è£…å™¨
                unwrapped_tool = tool
                wrapper_count = 0

                # è§£åŒ…ç›´åˆ°çœŸå®å·¥å…·
                while hasattr(unwrapped_tool, "wrapped_tool") and not isinstance(unwrapped_tool, ValidatedTool):
                    unwrapped_tool = unwrapped_tool.wrapped_tool
                    wrapper_count += 1
                    if wrapper_count > _MAX_WRAPPER_DEPTH:  # æ³¨æ„ï¼šé˜²æ­¢æ— é™å¾ªç¯
                        break

                # ä» `LangChain` å·¥å…·æ„å»ºè§„æ ¼
                tool_spec = {
                    "type": "function",
                    "function": {
                        "name": unwrapped_tool.name,
                        "description": unwrapped_tool.description or f"Tool: {unwrapped_tool.name}",
                        "parameters": {
                            "type": "object",
                            "properties": {},
                            "required": [],
                        },
                    },
                }

                # è‹¥å¯ç”¨åˆ™ä» `schema` æå–å‚æ•°
                args_dict = unwrapped_tool.args
                if isinstance(args_dict, dict):
                    for param_name, param_info in args_dict.items():
                        logger.debug(f"Processing parameter: {param_name}")
                        logger.debug(f"Parameter info: {param_info}")

                        # ä½¿ç”¨æ–°çš„è½¬æ¢å‡½æ•°
                        param_spec = _convert_pydantic_type_to_json_schema_type(param_info)

                        # é€šè¿‡ `Pydantic` å­—æ®µåˆ¤æ–­å‚æ•°æ˜¯å¦å¿…å¡«
                        if unwrapped_tool.args_schema and hasattr(unwrapped_tool.args_schema, "model_fields"):
                            field_info = unwrapped_tool.args_schema.model_fields.get(param_name)
                            if field_info and field_info.is_required():
                                tool_spec["function"]["parameters"]["required"].append(param_name)

                        tool_spec["function"]["parameters"]["properties"][param_name] = param_spec

                tool_specs.append(tool_spec)

            except (AttributeError, KeyError, TypeError, ValueError) as e:
                logger.warning(f"Could not convert tool {getattr(tool, 'name', 'unknown')} to spec: {e}")
                # åˆ›å»ºæœ€å°è§„æ ¼
                minimal_spec = {
                    "type": "function",
                    "function": {
                        "name": getattr(tool, "name", f"unknown_tool_{i}"),
                        "description": getattr(
                            tool,
                            "description",
                            f"Tool: {getattr(tool, 'name', 'unknown')}",
                        ),
                        "parameters": {
                            "type": "object",
                            "properties": {},
                            "required": [],
                        },
                    },
                }
                tool_specs.append(minimal_spec)

        if not tool_specs:
            logger.error("âš ï¸ No tool specs were generated! This will cause SPARC validation to fail")
        return tool_specs


class PostToolProcessor(ALTKBaseTool):
    """å¤„ç†å·¥å…·è¾“å‡ºçš„å·¥å…·è¾“å‡ºå¤„ç†å™¨

    æ­¤åŒ…è£…å™¨æ‹¦æˆªå·¥å…·æ‰§è¡Œè¾“å‡ºï¼Œå¦‚æœå·¥å…·è¾“å‡ºæ˜¯ JSONï¼Œ
    å®ƒä¼šè°ƒç”¨ ALTK ç»„ä»¶é€šè¿‡ç”Ÿæˆ Python ä»£ç ä» JSON ä¸­æå–ä¿¡æ¯ã€‚
    
    å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
    1) æ‰§è¡Œè¢«åŒ…è£…çš„å·¥å…·
    2) æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸º JSON æ ¼å¼
    3) å¦‚æœæ˜¯å¤§ JSONï¼Œåˆ™ä½¿ç”¨ä»£ç ç”Ÿæˆç»„ä»¶å¤„ç†
    
    å¼‚å¸¸æµï¼šåå¤„ç†å¤±è´¥æ—¶è¿”å›åŸå§‹ç»“æœã€‚
    æ€§èƒ½ç“¶é¢ˆï¼šä»£ç ç”Ÿæˆç»„ä»¶æ‰§è¡Œæ—¶ã€‚
    æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "Error in post-processing tool response"ã€"Exception in executing CodeGenerationComponent"ã€‚
    
    å¥‘çº¦ï¼š
    - è¾“å…¥ï¼šè¢«åŒ…è£…çš„å·¥å…·ã€ç”¨æˆ·æŸ¥è¯¢ã€ä»£ç†å’Œå…¶ä»–å‚æ•°
    - è¾“å‡ºï¼šPostToolProcessor å®ä¾‹
    - å‰¯ä½œç”¨ï¼šç»§æ‰¿è‡ª ALTKBaseTool çš„åŠŸèƒ½
    - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœåå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹å·¥å…·ç»“æœ
    """

    user_query: str = Field(...)
    response_processing_size_threshold: int = Field(...)

    def __init__(
        self,
        wrapped_tool: BaseTool,
        user_query: str,
        agent,
        response_processing_size_threshold: int,
        **kwargs,
    ):
        """åˆå§‹åŒ–åå·¥å…·å¤„ç†å™¨

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šè¢«åŒ…è£…çš„å·¥å…·ã€ç”¨æˆ·æŸ¥è¯¢ã€ä»£ç†ç­‰å‚æ•°
        - è¾“å‡ºï¼šPostToolProcessor å®ä¾‹
        - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ–çˆ¶ç±»å’Œæ‰€æœ‰å­—æ®µ
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼ŒæŠ›å‡ºç›¸åº”å¼‚å¸¸
        """
        super().__init__(
            name=wrapped_tool.name,
            description=wrapped_tool.description,
            wrapped_tool=wrapped_tool,
            user_query=user_query,
            agent=agent,
            response_processing_size_threshold=response_processing_size_threshold,
            **kwargs,
        )

    def _run(self, *args: Any, **kwargs: Any) -> str:
        """æ‰§è¡Œå·¥å…·å¹¶å¤„ç†ç»“æœ

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°
        - è¾“å‡ºï¼šå¤„ç†åçš„ç»“æœå­—ç¬¦ä¸²
        - å‰¯ä½œç”¨ï¼šæ‰§è¡Œè¢«åŒ…è£…çš„å·¥å…·å’Œåå¤„ç†
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœåå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ
        """
        # æ‰§è¡Œå·²åŒ…è£…çš„å·¥å…·
        result = self._execute_tool(*args, **kwargs)

        try:
            # æ‰§è¡Œåå¤„ç†å¹¶è¿”å›ç»“æœ
            return self.process_tool_response(result)
        except (AttributeError, TypeError, ValueError, RuntimeError) as e:
            # åå¤„ç†å¤±è´¥åˆ™è®°å½•é”™è¯¯å¹¶è¿”å›åŸç»“æœ
            logger.error(f"Error in post-processing tool response: {e}")
            return result

    def _get_tool_response_str(self, tool_response) -> str:
        """å°†å„ç§å·¥å…·å“åº”æ ¼å¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤º

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šå·¥å…·å“åº”ï¼ˆå¤šç§å¯èƒ½çš„ç±»å‹ï¼‰
        - è¾“å‡ºï¼šå­—ç¬¦ä¸²è¡¨ç¤ºçš„å·¥å…·å“åº”
        - å‰¯ä½œç”¨ï¼šæ— 
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœå“åº”ä¸º Noneï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if isinstance(tool_response, str):
            tool_response_str = tool_response
        elif isinstance(tool_response, Data):
            tool_response_str = str(tool_response.data)
        elif isinstance(tool_response, list) and all(isinstance(item, Data) for item in tool_response):
            # ä»…å–é¦–å…ƒç´ ï¼ˆæ˜¯å¦åº”å–é¦–æˆ–æœ«ä»å¾…ç¡®è®¤ï¼‰
            tool_response_str = str(tool_response[0].data)
        elif isinstance(tool_response, (dict, list)):
            tool_response_str = str(tool_response)
        else:
            # è¿”å›ç©ºå­—ç¬¦ä¸²è€Œé `None` ä»¥é¿å…ç±»å‹é”™è¯¯
            tool_response_str = str(tool_response) if tool_response is not None else ""

        return tool_response_str

    def process_tool_response(self, tool_response: str, **_kwargs) -> str:
        """å¤„ç†å·¥å…·å“åº”

        å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
        1) æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºé”™è¯¯æ¶ˆæ¯
        2) å°è¯•å°†å“åº”è§£æä¸º JSON
        3) å¦‚æœæ˜¯å¤§ JSONï¼Œåˆ™ä½¿ç”¨ä»£ç ç”Ÿæˆç»„ä»¶å¤„ç†

        å¼‚å¸¸æµï¼šJSON è§£æå¤±è´¥æ—¶è·³è¿‡ä»£ç ç”Ÿæˆã€‚
        æ€§èƒ½ç“¶é¢ˆï¼šä»£ç ç”Ÿæˆç»„ä»¶æ‰§è¡Œæ—¶ã€‚
        æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "An error in converting the tool response to json"ã€"Output of CodeGenerationComponent"ã€‚
        
        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šå·¥å…·å“åº”å­—ç¬¦ä¸²å’Œå…¶ä»–å‚æ•°
        - è¾“å‡ºï¼šå¤„ç†åçš„å“åº”å­—ç¬¦ä¸²
        - å‰¯ä½œç”¨ï¼šå¯èƒ½è°ƒç”¨ä»£ç ç”Ÿæˆç»„ä»¶
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹å·¥å…·å“åº”
        """
        logger.info("Calling process_tool_response of PostToolProcessor")
        tool_response_str = self._get_tool_response_str(tool_response)

        # å…ˆåˆ¤æ–­æ˜¯å¦ä¸ºå¸¦é¡¹ç›®ç¬¦å·çš„é”™è¯¯æ¶ˆæ¯ï¼ˆ`SPARC` æ‹’ç»ï¼‰
        if "âŒ" in tool_response_str or "â€¢" in tool_response_str:
            logger.info("Detected error message with special characters, skipping JSON parsing")
            return tool_response_str

        try:
        # ä»…å¯¹ç–‘ä¼¼ `JSON` çš„å†…å®¹å°è¯•è§£æ
            if (tool_response_str.startswith("{") and tool_response_str.endswith("}")) or (
                tool_response_str.startswith("[") and tool_response_str.endswith("]")
            ):
                tool_response_json = ast.literal_eval(tool_response_str)
                if not isinstance(tool_response_json, (list, dict)):
                    tool_response_json = None
            else:
                tool_response_json = None
        except (json.JSONDecodeError, TypeError, SyntaxError, ValueError) as e:
            logger.info(
                f"An error in converting the tool response to json, this will skip the code generation component: {e}"
            )
            tool_response_json = None

        if tool_response_json is not None and len(str(tool_response_json)) > self.response_processing_size_threshold:
            llm_client_obj = self._get_altk_llm_object(use_output_val=False)
            if llm_client_obj is not None:
                config = CodeGenerationComponentConfig(llm_client=llm_client_obj, use_docker_sandbox=False)

                middleware = CodeGenerationComponent(config=config)
                input_data = CodeGenerationRunInput(
                    messages=[],
                    nl_query=self.user_query,
                    tool_response=tool_response_json,
                )
                output = None
                try:
                    output = middleware.process(input_data, AgentPhase.RUNTIME)
                except Exception as e:  # noqa: BLE001
                    logger.error(f"Exception in executing CodeGenerationComponent: {e}")
                if output is not None and hasattr(output, "result"):
                    logger.info(f"Output of CodeGenerationComponent: {output.result}")
                    return output.result
        return tool_response


class PostToolProcessingWrapper(BaseToolWrapper):
    """æ·»åŠ åå·¥å…·å¤„ç†åŠŸèƒ½çš„å·¥å…·åŒ…è£…å™¨

    æ­¤åŒ…è£…å™¨å¤„ç†å·¥å…·è°ƒç”¨çš„è¾“å‡ºï¼Œç‰¹åˆ«æ˜¯ JSON å“åº”ï¼Œ
    ä½¿ç”¨ ALTK ä»£ç ç”Ÿæˆç»„ä»¶æå–æœ‰ç”¨ä¿¡æ¯ã€‚
    
    å¥‘çº¦ï¼š
    - è¾“å…¥ï¼šBaseTool å¯¹è±¡åŠé¢å¤–å‚æ•°
    - è¾“å‡ºï¼šå¸¦æœ‰åå¤„ç†åŠŸèƒ½çš„åŒ…è£…å·¥å…·
    - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ–åå¤„ç†ç»„ä»¶
    - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœåŒ…è£…å¤±è´¥ï¼Œè¿”å›åŸå§‹å·¥å…·
    """

    def __init__(self, response_processing_size_threshold: int = 100):
        """åˆå§‹åŒ–åå·¥å…·å¤„ç†åŒ…è£…å™¨

        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šå“åº”å¤„ç†å¤§å°é˜ˆå€¼
        - è¾“å‡ºï¼šPostToolProcessingWrapper å®ä¾‹
        - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ–é˜ˆå€¼å±æ€§
        - å¤±è´¥è¯­ä¹‰ï¼šæ— 
        """
        self.response_processing_size_threshold = response_processing_size_threshold

    def wrap_tool(self, tool: BaseTool, **kwargs) -> BaseTool:
        """ä½¿ç”¨åå¤„ç†åŠŸèƒ½åŒ…è£…å·¥å…·

        å…³é”®è·¯å¾„ï¼ˆä¸‰æ­¥ï¼‰ï¼š
        1) æ£€æŸ¥å·¥å…·æ˜¯å¦å·²è¢«ç›¸åŒåŒ…è£…å™¨åŒ…è£…
        2) éªŒè¯å¿…è¦å‚æ•°æ˜¯å¦å­˜åœ¨
        3) åº”ç”¨åå¤„ç†åŒ…è£…å™¨

        å¼‚å¸¸æµï¼šç¼ºå°‘ä»£ç†å‚æ•°æ—¶è¿”å›åŸå§‹å·¥å…·ã€‚
        æ€§èƒ½ç“¶é¢ˆï¼šæ— æ˜¾è‘—æ€§èƒ½ç“¶é¢ˆã€‚
        æ’éšœå…¥å£ï¼šæ—¥å¿—å…³é”®å­— "Cannot wrap tool with PostToolProcessor"ã€‚
        
        å¥‘çº¦ï¼š
        - è¾“å…¥ï¼šBaseTool å¯¹è±¡å’Œå…³é”®å­—å‚æ•°
        - è¾“å‡ºï¼šåŒ…è£…åçš„ BaseTool å¯¹è±¡
        - å‰¯ä½œç”¨ï¼šåˆå§‹åŒ–åå¤„ç†ç»„ä»¶
        - å¤±è´¥è¯­ä¹‰ï¼šå¦‚æœå¿…è¦å‚æ•°ç¼ºå¤±ï¼Œè¿”å›åŸå§‹å·¥å…·
        """
        logger.info(f"Post-tool reflection enabled for {tool.name}")
        if isinstance(tool, PostToolProcessor):
            # å·²è¢«è¯¥åŒ…è£…å™¨åŒ…è£¹åˆ™ç›´æ¥è¿”å›
            return tool

        # å¿…éœ€çš„ `kwargs`
        agent = kwargs.get("agent")
        user_query = kwargs.get("user_query", "")

        if not agent:
            logger.warning("Cannot wrap tool with PostToolProcessor: missing 'agent'")
            return tool

        # è‹¥å·¥å…·å·²è¢«å…¶ä»–åŒ…è£…å™¨åŒ…è£¹ï¼Œåˆ™éœ€è·å–æœ€å†…å±‚å·¥å…·
        actual_tool = tool

        return PostToolProcessor(
            wrapped_tool=actual_tool,
            user_query=user_query,
            agent=agent,
            response_processing_size_threshold=self.response_processing_size_threshold,
        )
